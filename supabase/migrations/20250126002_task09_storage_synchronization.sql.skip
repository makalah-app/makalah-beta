-- Migration: Task 09 - Storage Synchronization System
-- Description: Database-storage synchronization dengan real-time consistency
-- Author: Database Architect - Task 09 Implementation
-- Date: 2025-01-26

-- =====================================================
-- SYNCHRONIZATION STATUS TRACKING
-- =====================================================

-- Create sync status enum
CREATE TYPE sync_status AS ENUM (
    'pending',
    'in_progress', 
    'synchronized',
    'error',
    'orphaned',
    'conflict'
);

-- Create sync operation enum
CREATE TYPE sync_operation AS ENUM (
    'upload',
    'download',
    'delete',
    'move',
    'copy',
    'verify',
    'cleanup'
);

-- Create sync queue table
CREATE TABLE IF NOT EXISTS public.storage_sync_queue (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    artifact_id UUID NOT NULL REFERENCES public.artifacts(id) ON DELETE CASCADE,
    operation sync_operation NOT NULL,
    status sync_status DEFAULT 'pending' NOT NULL,
    source_path TEXT NULL,
    target_path TEXT NOT NULL,
    file_size BIGINT NULL,
    content_hash VARCHAR(64) NULL,
    retry_count INTEGER DEFAULT 0 NOT NULL,
    max_retries INTEGER DEFAULT 3 NOT NULL,
    priority INTEGER DEFAULT 5 CHECK (priority BETWEEN 1 AND 10),
    metadata JSONB DEFAULT '{}'::jsonb,
    error_message TEXT NULL,
    started_at TIMESTAMPTZ NULL,
    completed_at TIMESTAMPTZ NULL,
    next_retry_at TIMESTAMPTZ NULL,
    created_by UUID REFERENCES public.users(id),
    created_at TIMESTAMPTZ DEFAULT NOW() NOT NULL,
    updated_at TIMESTAMPTZ DEFAULT NOW() NOT NULL
);

-- Create indexes for sync queue performance
CREATE INDEX IF NOT EXISTS idx_sync_queue_status ON public.storage_sync_queue(status);
CREATE INDEX IF NOT EXISTS idx_sync_queue_operation ON public.storage_sync_queue(operation);
CREATE INDEX IF NOT EXISTS idx_sync_queue_artifact_id ON public.storage_sync_queue(artifact_id);
CREATE INDEX IF NOT EXISTS idx_sync_queue_priority ON public.storage_sync_queue(priority, created_at);
CREATE INDEX IF NOT EXISTS idx_sync_queue_retry ON public.storage_sync_queue(next_retry_at) WHERE status = 'error';
CREATE INDEX IF NOT EXISTS idx_sync_queue_pending ON public.storage_sync_queue(priority, created_at) WHERE status = 'pending';

-- Create updated_at trigger
CREATE TRIGGER update_sync_queue_updated_at
    BEFORE UPDATE ON public.storage_sync_queue
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

-- =====================================================
-- SYNCHRONIZATION FUNCTIONS
-- =====================================================

-- Function to enqueue storage operation
CREATE OR REPLACE FUNCTION enqueue_storage_sync(
    artifact_uuid UUID,
    sync_operation sync_operation,
    target_path_val TEXT,
    source_path_val TEXT DEFAULT NULL,
    priority_val INTEGER DEFAULT 5,
    metadata_val JSONB DEFAULT '{}'::jsonb
)
RETURNS UUID AS $$
DECLARE
    sync_id UUID;
    user_uuid UUID;
BEGIN
    user_uuid := auth.user_id();
    
    -- Create sync queue entry
    INSERT INTO public.storage_sync_queue (
        artifact_id,
        operation,
        source_path,
        target_path,
        priority,
        metadata,
        created_by
    ) VALUES (
        artifact_uuid,
        sync_operation,
        source_path_val,
        target_path_val,
        priority_val,
        metadata_val,
        user_uuid
    ) RETURNING id INTO sync_id;
    
    -- Update artifact sync status
    UPDATE public.artifacts
    SET processing_status = 'processing',
        updated_at = NOW()
    WHERE id = artifact_uuid;
    
    RETURN sync_id;
END;
$$ LANGUAGE plpgsql;

-- Function to process sync queue item
CREATE OR REPLACE FUNCTION process_sync_queue_item(sync_queue_id UUID)
RETURNS BOOLEAN AS $$
DECLARE
    sync_record RECORD;
    artifact_record RECORD;
    success BOOLEAN := false;
BEGIN
    -- Get sync record
    SELECT * INTO sync_record
    FROM public.storage_sync_queue
    WHERE id = sync_queue_id AND status = 'pending';
    
    IF NOT FOUND THEN
        RETURN false;
    END IF;
    
    -- Update status to in_progress
    UPDATE public.storage_sync_queue
    SET status = 'in_progress',
        started_at = NOW(),
        updated_at = NOW()
    WHERE id = sync_queue_id;
    
    -- Get artifact details
    SELECT * INTO artifact_record
    FROM public.artifacts
    WHERE id = sync_record.artifact_id;
    
    -- Process based on operation type
    CASE sync_record.operation
        WHEN 'upload' THEN
            success := sync_file_upload(sync_record, artifact_record);
        WHEN 'download' THEN
            success := sync_file_download(sync_record, artifact_record);
        WHEN 'delete' THEN
            success := sync_file_delete(sync_record, artifact_record);
        WHEN 'move' THEN
            success := sync_file_move(sync_record, artifact_record);
        WHEN 'copy' THEN
            success := sync_file_copy(sync_record, artifact_record);
        WHEN 'verify' THEN
            success := sync_file_verify(sync_record, artifact_record);
        WHEN 'cleanup' THEN
            success := sync_file_cleanup(sync_record, artifact_record);
        ELSE
            success := false;
    END CASE;
    
    -- Update sync status
    IF success THEN
        UPDATE public.storage_sync_queue
        SET status = 'synchronized',
            completed_at = NOW(),
            updated_at = NOW()
        WHERE id = sync_queue_id;
        
        -- Update artifact processing status
        UPDATE public.artifacts
        SET processing_status = 'completed',
            updated_at = NOW()
        WHERE id = sync_record.artifact_id;
    ELSE
        -- Handle failure dengan retry logic
        UPDATE public.storage_sync_queue
        SET status = CASE 
                WHEN retry_count >= max_retries THEN 'error'::sync_status
                ELSE 'pending'::sync_status
            END,
            retry_count = retry_count + 1,
            next_retry_at = NOW() + (INTERVAL '5 minutes' * (retry_count + 1)),
            error_message = CASE 
                WHEN retry_count >= max_retries THEN 'Max retries exceeded'
                ELSE error_message
            END,
            updated_at = NOW()
        WHERE id = sync_queue_id;
    END IF;
    
    RETURN success;
EXCEPTION
    WHEN OTHERS THEN
        -- Update with error status
        UPDATE public.storage_sync_queue
        SET status = 'error',
            error_message = SQLERRM,
            updated_at = NOW()
        WHERE id = sync_queue_id;
        
        RETURN false;
END;
$$ LANGUAGE plpgsql;

-- Function to verify file integrity
CREATE OR REPLACE FUNCTION verify_file_integrity(
    artifact_uuid UUID,
    expected_hash VARCHAR(64) DEFAULT NULL
)
RETURNS JSONB AS $$
DECLARE
    artifact_record RECORD;
    verification_result JSONB;
    storage_exists BOOLEAN := false;
    size_match BOOLEAN := false;
    hash_match BOOLEAN := false;
BEGIN
    -- Get artifact details
    SELECT * INTO artifact_record
    FROM public.artifacts
    WHERE id = artifact_uuid;
    
    IF NOT FOUND THEN
        RETURN jsonb_build_object(
            'success', false,
            'error', 'Artifact not found'
        );
    END IF;
    
    -- Simulate storage verification (would integrate dengan actual Supabase Storage API)
    storage_exists := (artifact_record.file_path IS NOT NULL);
    size_match := (artifact_record.file_size IS NOT NULL AND artifact_record.file_size > 0);
    
    -- Hash verification
    IF expected_hash IS NOT NULL THEN
        hash_match := (artifact_record.content_hash = expected_hash);
    ELSE
        hash_match := (artifact_record.content_hash IS NOT NULL);
    END IF;
    
    verification_result := jsonb_build_object(
        'artifact_id', artifact_uuid,
        'file_path', artifact_record.file_path,
        'storage_exists', storage_exists,
        'size_match', size_match,
        'hash_match', hash_match,
        'file_size', artifact_record.file_size,
        'content_hash', artifact_record.content_hash,
        'verified_at', NOW()
    );
    
    -- Log verification result
    INSERT INTO public.artifact_metadata (
        artifact_id,
        category,
        metadata_key,
        metadata_value,
        data_type,
        computed_by
    ) VALUES (
        artifact_uuid,
        'processing_info',
        'integrity_verification',
        verification_result,
        'object',
        'system'
    ) ON CONFLICT (artifact_id, category, metadata_key)
    DO UPDATE SET
        metadata_value = verification_result,
        updated_at = NOW();
    
    RETURN verification_result;
END;
$$ LANGUAGE plpgsql;

-- =====================================================
-- SYNCHRONIZATION OPERATION HELPERS
-- =====================================================

-- Helper function untuk upload sync (placeholder)
CREATE OR REPLACE FUNCTION sync_file_upload(
    sync_record RECORD,
    artifact_record RECORD
)
RETURNS BOOLEAN AS $$
BEGIN
    -- Placeholder for actual storage upload integration
    -- Would use Supabase Storage API
    
    -- Update artifact dengan upload success
    UPDATE public.artifacts
    SET file_path = sync_record.target_path,
        processing_status = 'completed',
        updated_at = NOW()
    WHERE id = artifact_record.id;
    
    RETURN true;
EXCEPTION
    WHEN OTHERS THEN
        RETURN false;
END;
$$ LANGUAGE plpgsql;

-- Helper function untuk download sync (placeholder)
CREATE OR REPLACE FUNCTION sync_file_download(
    sync_record RECORD,
    artifact_record RECORD
)
RETURNS BOOLEAN AS $$
BEGIN
    -- Placeholder for actual storage download integration
    -- Would use Supabase Storage API
    
    -- Update access tracking
    UPDATE public.artifacts
    SET last_accessed_at = NOW(),
        download_count = download_count + 1,
        updated_at = NOW()
    WHERE id = artifact_record.id;
    
    RETURN true;
EXCEPTION
    WHEN OTHERS THEN
        RETURN false;
END;
$$ LANGUAGE plpgsql;

-- Helper function untuk delete sync
CREATE OR REPLACE FUNCTION sync_file_delete(
    sync_record RECORD,
    artifact_record RECORD
)
RETURNS BOOLEAN AS $$
BEGIN
    -- Update artifact status instead of hard delete
    UPDATE public.artifacts
    SET status = 'deleted',
        file_path = NULL,
        updated_at = NOW()
    WHERE id = artifact_record.id;
    
    RETURN true;
EXCEPTION
    WHEN OTHERS THEN
        RETURN false;
END;
$$ LANGUAGE plpgsql;

-- Helper function untuk move sync
CREATE OR REPLACE FUNCTION sync_file_move(
    sync_record RECORD,
    artifact_record RECORD
)
RETURNS BOOLEAN AS $$
BEGIN
    -- Update artifact dengan new path
    UPDATE public.artifacts
    SET file_path = sync_record.target_path,
        updated_at = NOW()
    WHERE id = artifact_record.id;
    
    RETURN true;
EXCEPTION
    WHEN OTHERS THEN
        RETURN false;
END;
$$ LANGUAGE plpgsql;

-- Helper function untuk copy sync
CREATE OR REPLACE FUNCTION sync_file_copy(
    sync_record RECORD,
    artifact_record RECORD
)
RETURNS BOOLEAN AS $$
BEGIN
    -- Placeholder for storage copy operation
    -- Would integrate dengan Supabase Storage API
    RETURN true;
EXCEPTION
    WHEN OTHERS THEN
        RETURN false;
END;
$$ LANGUAGE plpgsql;

-- Helper function untuk verify sync
CREATE OR REPLACE FUNCTION sync_file_verify(
    sync_record RECORD,
    artifact_record RECORD
)
RETURNS BOOLEAN AS $$
DECLARE
    verification JSONB;
BEGIN
    verification := verify_file_integrity(artifact_record.id);
    
    RETURN (verification->>'storage_exists')::BOOLEAN 
           AND (verification->>'size_match')::BOOLEAN 
           AND (verification->>'hash_match')::BOOLEAN;
END;
$$ LANGUAGE plpgsql;

-- Helper function untuk cleanup sync
CREATE OR REPLACE FUNCTION sync_file_cleanup(
    sync_record RECORD,
    artifact_record RECORD
)
RETURNS BOOLEAN AS $$
BEGIN
    -- Clean up orphaned records
    IF artifact_record.status = 'deleted' AND artifact_record.updated_at < NOW() - INTERVAL '30 days' THEN
        -- Perform actual deletion
        DELETE FROM public.artifacts WHERE id = artifact_record.id;
        RETURN true;
    END IF;
    
    RETURN true;
EXCEPTION
    WHEN OTHERS THEN
        RETURN false;
END;
$$ LANGUAGE plpgsql;

-- =====================================================
-- BATCH PROCESSING FUNCTIONS
-- =====================================================

-- Function to process sync queue dalam batches
CREATE OR REPLACE FUNCTION process_sync_queue_batch(batch_size INTEGER DEFAULT 10)
RETURNS TABLE(
    processed_count INTEGER,
    success_count INTEGER,
    error_count INTEGER,
    processing_time INTERVAL
) AS $$
DECLARE
    start_time TIMESTAMPTZ;
    end_time TIMESTAMPTZ;
    total_processed INTEGER := 0;
    total_success INTEGER := 0;
    total_errors INTEGER := 0;
    sync_item RECORD;
    item_success BOOLEAN;
BEGIN
    start_time := NOW();
    
    -- Process pending items in priority order
    FOR sync_item IN (
        SELECT id
        FROM public.storage_sync_queue
        WHERE status = 'pending' 
        OR (status = 'error' AND next_retry_at <= NOW())
        ORDER BY priority DESC, created_at ASC
        LIMIT batch_size
    ) LOOP
        item_success := process_sync_queue_item(sync_item.id);
        total_processed := total_processed + 1;
        
        IF item_success THEN
            total_success := total_success + 1;
        ELSE
            total_errors := total_errors + 1;
        END IF;
    END LOOP;
    
    end_time := NOW();
    
    processed_count := total_processed;
    success_count := total_success;
    error_count := total_errors;
    processing_time := end_time - start_time;
    
    RETURN NEXT;
END;
$$ LANGUAGE plpgsql;

-- =====================================================
-- MONITORING AND REPORTING
-- =====================================================

-- Function to get sync queue status
CREATE OR REPLACE FUNCTION get_sync_queue_status()
RETURNS TABLE(
    status sync_status,
    operation sync_operation,
    count BIGINT,
    avg_retry_count NUMERIC,
    oldest_created TIMESTAMPTZ
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        ssq.status,
        ssq.operation,
        COUNT(*) as count,
        ROUND(AVG(ssq.retry_count), 2) as avg_retry_count,
        MIN(ssq.created_at) as oldest_created
    FROM public.storage_sync_queue ssq
    WHERE ssq.created_at > NOW() - INTERVAL '7 days'
    GROUP BY ssq.status, ssq.operation
    ORDER BY ssq.status, count DESC;
END;
$$ LANGUAGE plpgsql;

-- Function to detect orphaned files
CREATE OR REPLACE FUNCTION detect_orphaned_files()
RETURNS TABLE(
    artifact_id UUID,
    file_path TEXT,
    orphan_type TEXT,
    detected_at TIMESTAMPTZ
) AS $$
BEGIN
    RETURN QUERY
    -- Files in database but missing from storage (simulated)
    SELECT 
        a.id,
        a.file_path,
        'database_orphan' as orphan_type,
        NOW() as detected_at
    FROM public.artifacts a
    WHERE a.file_path IS NOT NULL 
    AND a.status = 'active'
    AND NOT EXISTS (
        SELECT 1 FROM public.storage_sync_queue ssq 
        WHERE ssq.artifact_id = a.id 
        AND ssq.status = 'synchronized'
        AND ssq.target_path = a.file_path
    );
END;
$$ LANGUAGE plpgsql;

-- Enable RLS
ALTER TABLE public.storage_sync_queue ENABLE ROW LEVEL SECURITY;

-- =====================================================
-- COMMENTS AND DOCUMENTATION
-- =====================================================

COMMENT ON TABLE public.storage_sync_queue IS 'Queue for managing storage synchronization operations';
COMMENT ON FUNCTION enqueue_storage_sync() IS 'Adds storage operation to sync queue dengan priority';
COMMENT ON FUNCTION process_sync_queue_item() IS 'Processes individual sync queue item dengan retry logic';
COMMENT ON FUNCTION verify_file_integrity() IS 'Verifies file integrity between database dan storage';
COMMENT ON FUNCTION process_sync_queue_batch() IS 'Processes sync queue dalam batches untuk performance';
COMMENT ON FUNCTION get_sync_queue_status() IS 'Returns sync queue status dan statistics';
COMMENT ON FUNCTION detect_orphaned_files() IS 'Detects files yang exist in database but missing from storage';