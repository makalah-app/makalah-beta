-- Migration: Task 09 - Storage Configuration and Monitoring
-- Description: Storage monitoring, quota management, dan performance analytics
-- Author: Database Architect - Task 09 Implementation
-- Date: 2025-01-26

-- =====================================================
-- STORAGE CONFIGURATION TABLES
-- =====================================================

-- Create storage configuration table
CREATE TABLE IF NOT EXISTS public.storage_configuration (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    bucket_name VARCHAR(100) NOT NULL UNIQUE,
    max_file_size BIGINT NOT NULL, -- in bytes
    allowed_mime_types TEXT[] NOT NULL,
    retention_period INTERVAL DEFAULT '1 year',
    cleanup_enabled BOOLEAN DEFAULT true,
    quota_per_user BIGINT DEFAULT 1073741824, -- 1GB default
    public_access BOOLEAN DEFAULT false,
    versioning_enabled BOOLEAN DEFAULT true,
    compression_enabled BOOLEAN DEFAULT false,
    encryption_required BOOLEAN DEFAULT true,
    metadata JSONB DEFAULT '{}'::jsonb,
    created_at TIMESTAMPTZ DEFAULT NOW() NOT NULL,
    updated_at TIMESTAMPTZ DEFAULT NOW() NOT NULL
);

-- Create storage quota tracking table
CREATE TABLE IF NOT EXISTS public.storage_quota_usage (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    user_id UUID NOT NULL REFERENCES public.users(id) ON DELETE CASCADE,
    bucket_name VARCHAR(100) NOT NULL,
    current_usage BIGINT DEFAULT 0 NOT NULL,
    quota_limit BIGINT NOT NULL,
    file_count INTEGER DEFAULT 0 NOT NULL,
    last_calculated_at TIMESTAMPTZ DEFAULT NOW() NOT NULL,
    warning_sent_at TIMESTAMPTZ NULL,
    quota_exceeded BOOLEAN DEFAULT false NOT NULL,
    created_at TIMESTAMPTZ DEFAULT NOW() NOT NULL,
    updated_at TIMESTAMPTZ DEFAULT NOW() NOT NULL,
    UNIQUE(user_id, bucket_name)
);

-- Create storage performance metrics table
CREATE TABLE IF NOT EXISTS public.storage_performance_metrics (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    bucket_name VARCHAR(100) NOT NULL,
    operation_type VARCHAR(50) NOT NULL, -- 'upload', 'download', 'delete', 'list'
    file_size_category VARCHAR(20) NOT NULL, -- 'small', 'medium', 'large', 'xlarge'
    avg_duration_ms INTEGER NOT NULL,
    success_rate DECIMAL(5,2) NOT NULL,
    error_count INTEGER DEFAULT 0,
    total_operations INTEGER NOT NULL,
    measured_at TIMESTAMPTZ DEFAULT NOW() NOT NULL,
    measurement_period INTERVAL DEFAULT '1 hour',
    created_at TIMESTAMPTZ DEFAULT NOW() NOT NULL
);

-- Create indexes
CREATE INDEX IF NOT EXISTS idx_storage_quota_user_bucket ON public.storage_quota_usage(user_id, bucket_name);
CREATE INDEX IF NOT EXISTS idx_storage_quota_exceeded ON public.storage_quota_usage(quota_exceeded) WHERE quota_exceeded = true;
CREATE INDEX IF NOT EXISTS idx_storage_performance_bucket ON public.storage_performance_metrics(bucket_name, operation_type);
CREATE INDEX IF NOT EXISTS idx_storage_performance_measured ON public.storage_performance_metrics(measured_at);

-- Create updated_at triggers
CREATE TRIGGER update_storage_configuration_updated_at
    BEFORE UPDATE ON public.storage_configuration
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_storage_quota_updated_at
    BEFORE UPDATE ON public.storage_quota_usage
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

-- =====================================================
-- STORAGE CONFIGURATION FUNCTIONS
-- =====================================================

-- Function to initialize storage configuration
CREATE OR REPLACE FUNCTION initialize_storage_configuration()
RETURNS void AS $$
BEGIN
    -- Insert default bucket configurations
    INSERT INTO public.storage_configuration (
        bucket_name,
        max_file_size,
        allowed_mime_types,
        retention_period,
        quota_per_user,
        public_access,
        versioning_enabled,
        metadata
    ) VALUES 
    (
        'artifacts',
        104857600, -- 100MB
        ARRAY['application/pdf', 'text/plain', 'text/markdown', 'application/json', 'application/msword', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'],
        INTERVAL '2 years',
        2147483648, -- 2GB
        false,
        true,
        jsonb_build_object('description', 'Academic artifacts storage', 'priority', 'high')
    ),
    (
        'avatars',
        5242880, -- 5MB
        ARRAY['image/jpeg', 'image/png', 'image/webp'],
        INTERVAL '1 year',
        52428800, -- 50MB
        true,
        false,
        jsonb_build_object('description', 'User avatar images', 'priority', 'low')
    ),
    (
        'documents',
        52428800, -- 50MB
        ARRAY['application/pdf', 'text/plain', 'text/markdown', 'application/json', 'image/jpeg', 'image/png'],
        INTERVAL '1 year',
        1073741824, -- 1GB
        false,
        true,
        jsonb_build_object('description', 'General document storage', 'priority', 'medium')
    ),
    (
        'templates',
        20971520, -- 20MB
        ARRAY['text/plain', 'text/markdown', 'application/json', 'text/html'],
        INTERVAL '5 years',
        104857600, -- 100MB (admin only)
        true,
        true,
        jsonb_build_object('description', 'Document templates', 'priority', 'high')
    )
    ON CONFLICT (bucket_name) DO NOTHING;
END;
$$ LANGUAGE plpgsql;

-- Function to get storage configuration for bucket
CREATE OR REPLACE FUNCTION get_storage_config(bucket_name_param VARCHAR)
RETURNS public.storage_configuration AS $$
DECLARE
    config_record public.storage_configuration;
BEGIN
    SELECT * INTO config_record
    FROM public.storage_configuration
    WHERE bucket_name = bucket_name_param;
    
    IF NOT FOUND THEN
        RAISE EXCEPTION 'Storage configuration not found for bucket: %', bucket_name_param;
    END IF;
    
    RETURN config_record;
END;
$$ LANGUAGE plpgsql;

-- =====================================================
-- QUOTA MANAGEMENT FUNCTIONS
-- =====================================================

-- Function to calculate dan update user storage quota
CREATE OR REPLACE FUNCTION calculate_user_storage_quota(
    user_uuid UUID,
    bucket_name_param VARCHAR DEFAULT NULL
)
RETURNS void AS $$
DECLARE
    bucket_record RECORD;
    current_usage_val BIGINT;
    file_count_val INTEGER;
    quota_limit_val BIGINT;
BEGIN
    -- Process all buckets or specific bucket
    FOR bucket_record IN (
        SELECT bucket_name, quota_per_user
        FROM public.storage_configuration
        WHERE bucket_name_param IS NULL OR bucket_name = bucket_name_param
    ) LOOP
        -- Calculate current usage
        SELECT 
            COALESCE(SUM(file_size), 0),
            COUNT(*)
        INTO current_usage_val, file_count_val
        FROM public.artifacts
        WHERE user_id = user_uuid
        AND file_path LIKE bucket_record.bucket_name || '/%'
        AND status != 'deleted';
        
        quota_limit_val := bucket_record.quota_per_user;
        
        -- Insert or update quota usage
        INSERT INTO public.storage_quota_usage (
            user_id,
            bucket_name,
            current_usage,
            quota_limit,
            file_count,
            quota_exceeded,
            last_calculated_at
        ) VALUES (
            user_uuid,
            bucket_record.bucket_name,
            current_usage_val,
            quota_limit_val,
            file_count_val,
            current_usage_val > quota_limit_val,
            NOW()
        ) ON CONFLICT (user_id, bucket_name)
        DO UPDATE SET
            current_usage = current_usage_val,
            quota_limit = quota_limit_val,
            file_count = file_count_val,
            quota_exceeded = current_usage_val > quota_limit_val,
            last_calculated_at = NOW(),
            updated_at = NOW();
    END LOOP;
END;
$$ LANGUAGE plpgsql;

-- Function to check quota before file upload
CREATE OR REPLACE FUNCTION check_storage_quota(
    user_uuid UUID,
    bucket_name_param VARCHAR,
    file_size_bytes BIGINT
)
RETURNS BOOLEAN AS $$
DECLARE
    quota_record RECORD;
    would_exceed BOOLEAN;
BEGIN
    -- Get current quota usage
    SELECT current_usage, quota_limit, quota_exceeded
    INTO quota_record
    FROM public.storage_quota_usage
    WHERE user_id = user_uuid AND bucket_name = bucket_name_param;
    
    IF NOT FOUND THEN
        -- Initialize quota if not exists
        PERFORM calculate_user_storage_quota(user_uuid, bucket_name_param);
        
        SELECT current_usage, quota_limit, quota_exceeded
        INTO quota_record
        FROM public.storage_quota_usage
        WHERE user_id = user_uuid AND bucket_name = bucket_name_param;
    END IF;
    
    would_exceed := (quota_record.current_usage + file_size_bytes) > quota_record.quota_limit;
    
    RETURN NOT would_exceed;
END;
$$ LANGUAGE plpgsql;

-- Function to get quota status untuk user
CREATE OR REPLACE FUNCTION get_user_quota_status(user_uuid UUID)
RETURNS TABLE(
    bucket_name VARCHAR,
    current_usage BIGINT,
    quota_limit BIGINT,
    usage_percentage DECIMAL,
    files_count INTEGER,
    quota_exceeded BOOLEAN,
    available_space BIGINT
) AS $$
BEGIN
    -- Refresh quota calculations
    PERFORM calculate_user_storage_quota(user_uuid);
    
    RETURN QUERY
    SELECT 
        squ.bucket_name,
        squ.current_usage,
        squ.quota_limit,
        ROUND((squ.current_usage::DECIMAL / NULLIF(squ.quota_limit, 0)) * 100, 2) as usage_percentage,
        squ.file_count,
        squ.quota_exceeded,
        GREATEST(squ.quota_limit - squ.current_usage, 0) as available_space
    FROM public.storage_quota_usage squ
    WHERE squ.user_id = user_uuid
    ORDER BY squ.bucket_name;
END;
$$ LANGUAGE plpgsql;

-- =====================================================
-- PERFORMANCE MONITORING FUNCTIONS
-- =====================================================

-- Function to categorize file size
CREATE OR REPLACE FUNCTION categorize_file_size(size_bytes BIGINT)
RETURNS TEXT AS $$
BEGIN
    CASE
        WHEN size_bytes <= 1048576 THEN -- <= 1MB
            RETURN 'small';
        WHEN size_bytes <= 10485760 THEN -- <= 10MB
            RETURN 'medium';
        WHEN size_bytes <= 104857600 THEN -- <= 100MB
            RETURN 'large';
        ELSE
            RETURN 'xlarge';
    END CASE;
END;
$$ LANGUAGE plpgsql;

-- Function to record performance metrics
CREATE OR REPLACE FUNCTION record_storage_performance(
    bucket_name_param VARCHAR,
    operation_type_param VARCHAR,
    file_size_bytes BIGINT,
    duration_ms INTEGER,
    success BOOLEAN DEFAULT true
)
RETURNS void AS $$
DECLARE
    size_category TEXT;
    current_metrics RECORD;
BEGIN
    size_category := categorize_file_size(file_size_bytes);
    
    -- Get existing metrics for this hour
    SELECT 
        avg_duration_ms,
        success_rate,
        error_count,
        total_operations
    INTO current_metrics
    FROM public.storage_performance_metrics
    WHERE bucket_name = bucket_name_param
    AND operation_type = operation_type_param
    AND file_size_category = size_category
    AND measured_at >= DATE_TRUNC('hour', NOW())
    AND measured_at < DATE_TRUNC('hour', NOW()) + INTERVAL '1 hour';
    
    IF FOUND THEN
        -- Update existing metrics
        UPDATE public.storage_performance_metrics
        SET avg_duration_ms = ROUND((avg_duration_ms * total_operations + duration_ms) / (total_operations + 1)),
            success_rate = ROUND(
                CASE 
                    WHEN success THEN (success_rate * total_operations + 100) / (total_operations + 1)
                    ELSE (success_rate * total_operations) / (total_operations + 1)
                END, 2
            ),
            error_count = error_count + CASE WHEN success THEN 0 ELSE 1 END,
            total_operations = total_operations + 1
        WHERE bucket_name = bucket_name_param
        AND operation_type = operation_type_param
        AND file_size_category = size_category
        AND measured_at >= DATE_TRUNC('hour', NOW())
        AND measured_at < DATE_TRUNC('hour', NOW()) + INTERVAL '1 hour';
    ELSE
        -- Insert new metrics
        INSERT INTO public.storage_performance_metrics (
            bucket_name,
            operation_type,
            file_size_category,
            avg_duration_ms,
            success_rate,
            error_count,
            total_operations,
            measured_at
        ) VALUES (
            bucket_name_param,
            operation_type_param,
            size_category,
            duration_ms,
            CASE WHEN success THEN 100.00 ELSE 0.00 END,
            CASE WHEN success THEN 0 ELSE 1 END,
            1,
            DATE_TRUNC('hour', NOW())
        );
    END IF;
END;
$$ LANGUAGE plpgsql;

-- Function to get performance analytics
CREATE OR REPLACE FUNCTION get_storage_performance_analytics(
    bucket_name_param VARCHAR DEFAULT NULL,
    time_period INTERVAL DEFAULT '24 hours'
)
RETURNS TABLE(
    bucket_name VARCHAR,
    operation_type VARCHAR,
    file_size_category VARCHAR,
    avg_duration_ms DECIMAL,
    success_rate DECIMAL,
    total_operations BIGINT,
    error_count BIGINT,
    trend_direction TEXT
) AS $$
BEGIN
    RETURN QUERY
    WITH performance_data AS (
        SELECT 
            spm.bucket_name,
            spm.operation_type,
            spm.file_size_category,
            AVG(spm.avg_duration_ms) as avg_duration_ms,
            AVG(spm.success_rate) as success_rate,
            SUM(spm.total_operations) as total_operations,
            SUM(spm.error_count) as error_count,
            -- Simple trend calculation (compare first half vs second half)
            CASE 
                WHEN AVG(CASE WHEN spm.measured_at >= NOW() - (time_period / 2) THEN spm.avg_duration_ms END) >
                     AVG(CASE WHEN spm.measured_at < NOW() - (time_period / 2) THEN spm.avg_duration_ms END)
                THEN 'slower'
                WHEN AVG(CASE WHEN spm.measured_at >= NOW() - (time_period / 2) THEN spm.avg_duration_ms END) <
                     AVG(CASE WHEN spm.measured_at < NOW() - (time_period / 2) THEN spm.avg_duration_ms END)
                THEN 'faster'
                ELSE 'stable'
            END as trend_direction
        FROM public.storage_performance_metrics spm
        WHERE spm.measured_at >= NOW() - time_period
        AND (bucket_name_param IS NULL OR spm.bucket_name = bucket_name_param)
        GROUP BY spm.bucket_name, spm.operation_type, spm.file_size_category
    )
    SELECT 
        pd.bucket_name,
        pd.operation_type,
        pd.file_size_category,
        ROUND(pd.avg_duration_ms, 2) as avg_duration_ms,
        ROUND(pd.success_rate, 2) as success_rate,
        pd.total_operations,
        pd.error_count,
        pd.trend_direction
    FROM performance_data pd
    ORDER BY pd.bucket_name, pd.operation_type, pd.file_size_category;
END;
$$ LANGUAGE plpgsql;

-- =====================================================
-- CLEANUP AND MAINTENANCE FUNCTIONS  
-- =====================================================

-- Function to cleanup expired storage data
CREATE OR REPLACE FUNCTION cleanup_expired_storage_data()
RETURNS TABLE(
    cleanup_type TEXT,
    items_cleaned INTEGER,
    space_freed BIGINT
) AS $$
DECLARE
    artifacts_cleaned INTEGER := 0;
    space_freed_val BIGINT := 0;
    metrics_cleaned INTEGER := 0;
BEGIN
    -- Clean up old performance metrics (older than 30 days)
    DELETE FROM public.storage_performance_metrics
    WHERE measured_at < NOW() - INTERVAL '30 days';
    
    GET DIAGNOSTICS metrics_cleaned = ROW_COUNT;
    
    -- Clean up deleted artifacts (soft delete older than retention period)
    WITH deleted_artifacts AS (
        SELECT id, file_size
        FROM public.artifacts a
        JOIN public.storage_configuration sc ON a.file_path LIKE sc.bucket_name || '/%'
        WHERE a.status = 'deleted'
        AND a.updated_at < NOW() - sc.retention_period
    )
    DELETE FROM public.artifacts
    WHERE id IN (SELECT id FROM deleted_artifacts);
    
    GET DIAGNOSTICS artifacts_cleaned = ROW_COUNT;
    
    -- Calculate space freed (approximate)
    SELECT COALESCE(SUM(file_size), 0) INTO space_freed_val
    FROM public.artifacts
    WHERE status = 'deleted'
    AND updated_at < NOW() - INTERVAL '30 days';
    
    -- Return cleanup results
    cleanup_type := 'performance_metrics';
    items_cleaned := metrics_cleaned;
    space_freed := 0;
    RETURN NEXT;
    
    cleanup_type := 'expired_artifacts';
    items_cleaned := artifacts_cleaned;
    space_freed := space_freed_val;
    RETURN NEXT;
END;
$$ LANGUAGE plpgsql;

-- Function to get storage health report
CREATE OR REPLACE FUNCTION get_storage_health_report()
RETURNS JSONB AS $$
DECLARE
    health_report JSONB;
    bucket_stats JSONB;
    quota_alerts JSONB;
    performance_issues JSONB;
BEGIN
    -- Get bucket statistics
    SELECT jsonb_object_agg(
        bucket_name,
        jsonb_build_object(
            'total_files', total_files,
            'total_size', total_size,
            'avg_file_size', avg_file_size
        )
    ) INTO bucket_stats
    FROM (
        SELECT 
            SUBSTRING(file_path FROM '^([^/]+)') as bucket_name,
            COUNT(*) as total_files,
            SUM(file_size) as total_size,
            AVG(file_size) as avg_file_size
        FROM public.artifacts
        WHERE status = 'active' AND file_path IS NOT NULL
        GROUP BY SUBSTRING(file_path FROM '^([^/]+)')
    ) bucket_data;
    
    -- Get quota alerts
    SELECT jsonb_agg(
        jsonb_build_object(
            'user_id', user_id,
            'bucket_name', bucket_name,
            'usage_percentage', ROUND((current_usage::DECIMAL / quota_limit) * 100, 2)
        )
    ) INTO quota_alerts
    FROM public.storage_quota_usage
    WHERE quota_exceeded = true OR (current_usage::DECIMAL / quota_limit) > 0.8;
    
    -- Get performance issues
    SELECT jsonb_agg(
        jsonb_build_object(
            'bucket_name', bucket_name,
            'operation_type', operation_type,
            'avg_duration_ms', avg_duration_ms,
            'success_rate', success_rate
        )
    ) INTO performance_issues
    FROM (
        SELECT bucket_name, operation_type, avg_duration_ms, success_rate
        FROM public.storage_performance_metrics
        WHERE measured_at >= NOW() - INTERVAL '24 hours'
        AND (avg_duration_ms > 5000 OR success_rate < 95.0)
        ORDER BY avg_duration_ms DESC
        LIMIT 10
    ) issues;
    
    health_report := jsonb_build_object(
        'generated_at', NOW(),
        'bucket_statistics', COALESCE(bucket_stats, '{}'::jsonb),
        'quota_alerts', COALESCE(quota_alerts, '[]'::jsonb),
        'performance_issues', COALESCE(performance_issues, '[]'::jsonb),
        'total_active_artifacts', (
            SELECT COUNT(*) FROM public.artifacts WHERE status = 'active'
        ),
        'total_storage_used', (
            SELECT SUM(file_size) FROM public.artifacts WHERE status = 'active'
        )
    );
    
    RETURN health_report;
END;
$$ LANGUAGE plpgsql;

-- Initialize storage configuration
SELECT initialize_storage_configuration();

-- Enable RLS
ALTER TABLE public.storage_configuration ENABLE ROW LEVEL SECURITY;
ALTER TABLE public.storage_quota_usage ENABLE ROW LEVEL SECURITY;
ALTER TABLE public.storage_performance_metrics ENABLE ROW LEVEL SECURITY;

-- =====================================================
-- COMMENTS AND DOCUMENTATION
-- =====================================================

COMMENT ON TABLE public.storage_configuration IS 'Storage bucket configuration dan limits';
COMMENT ON TABLE public.storage_quota_usage IS 'User storage quota tracking per bucket';
COMMENT ON TABLE public.storage_performance_metrics IS 'Storage operation performance metrics';

COMMENT ON FUNCTION initialize_storage_configuration() IS 'Initializes default storage bucket configurations';
COMMENT ON FUNCTION calculate_user_storage_quota() IS 'Calculates dan updates user storage quota usage';
COMMENT ON FUNCTION check_storage_quota() IS 'Checks if file upload would exceed user quota';
COMMENT ON FUNCTION get_user_quota_status() IS 'Returns complete quota status untuk user';
COMMENT ON FUNCTION record_storage_performance() IS 'Records storage operation performance metrics';
COMMENT ON FUNCTION get_storage_performance_analytics() IS 'Returns storage performance analytics';
COMMENT ON FUNCTION cleanup_expired_storage_data() IS 'Cleans up expired storage data dan metrics';
COMMENT ON FUNCTION get_storage_health_report() IS 'Returns comprehensive storage system health report';